{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "As mentioned in the article, we use [Progressive Transformers SLP](https://github.com/BenSaunders27/ProgressiveTransformersSLP) as our basic model and [SignLanguageProcessing](https://github.com/gopeith/SignLanguageProcessing/tree/master/wacv2020) as our basic development tool for our new dataset. On the basis of these two works, we make innovative improvements, which are our contributions.\n",
    "\n",
    "## Data Preparation\n",
    "\n",
    "Firstly, place the JSON file output by OpenPose, which is approximately 24 frames per second, in a similar location in the repository. The 'video' folder next to it is for reference only.\n",
    "\n",
    "The input_data folder should have a 'dev.files' file for storing video names of dev subset and dev.text file for storing video dialogue text of dev subset. These two files can store more than five video information, and any excess video information will not be recorded in the final data. The tool will search for corresponding information in these two files based on the existing JSON folder names, and place the deleted/streamlined 'dev.files' and 'dev.text' files in the final folder. The generated pose and data will also be placed in this final folder.\n",
    "\n",
    "This jupyter notebook did not undergo comprehensive testing. If there are areas for optimization, you can submit a PR on GitHub.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import exists, join, basename, splitext\n",
    "os.chdir('/root')\n",
    "\n",
    "# Install Prompt2Sign\n",
    "# Firstly, obtain our tool, which comes with default data.\n",
    "!git clone https://github.com/SignLLM/Prompt2Sign.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/root/Prompt2Sign/tools/2D_to_3D')\n",
    "\n",
    "# Install Environment\n",
    "# If you already have this environment, skip this code\n",
    "!conda env create -f environment.yml -n tf15\n",
    "!conda activate tf15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing\n",
    "\n",
    "Use the following three steps to calculate the 3D keypoints from the numbers in the 2D keypoints (excluding head and leg calculations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/root/Prompt2Sign/tools/2D_to_3D')\n",
    "\n",
    "!conda activate tf15\n",
    "# Select the subset you want to work with, such as the dev set you want to work with How2Sign.\n",
    "data_mode='dev'\n",
    "!python pipeline_demo_01_json2h5.py --data_subset $data_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the subset you want to work with, such as the dev set you want to work with How2Sign.\n",
    "data_mode='dev'\n",
    "!python pipeline_demo_02_h5totxt.py --data_subset $data_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the subset you want to work with, such as the dev set you want to work with How2Sign.\n",
    "data_mode='dev'\n",
    "!python pipeline_demo_03_txt2skels.py --data_subset $data_mode"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf15",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
