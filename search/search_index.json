{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Prompt2Sign","text":"<p>Welcome to Prompt2Sign! This repository stores the preprocessed data for the paper: SignLLM: Sign Languages Production Large Language Models.</p> <p>Note: The release of our data is tentatively expected at the end of 2024, so don't rush.</p>"},{"location":"#news","title":"News","text":"<p>[2025.05.24] We have recently developed a tool named fast_dwpose for minimizing the extraction and visualization of DW Pose, and we hope it will be helpful to everyone. [2025.04.18] Surprise: We have released How2Sign new compressed data based on DWPose, and an upgraded version of the SignLLM-based application will be launched strongly in the future. [2025.04.01] IMPORTANT: We will try to provide a new compression solution (maybe based DWpose) at some point. Therefore, for unreleased preprocessed data and for existing data processing, the best approach is to download the original dataset and then process it using our processing tools. [2025.03.31] The prompt template has been updated, more data information has been updated. In the past, I've been wanting to optimize filtering, re-normalize according to body type and improve data quality, this make me have severe procrastination. And later I noticed that DWpose might be a better training method, so unreleased data will not be maintained because our time should spent on better data formats. [2024.06.30] The Jupyer Notebook and Docker for data processing has been released. [2024.05.17] The arXiv version of the paper is now available. [2024.01.16] Prompt2Sign homepage is available and data is expected to be released after accept (maybe at the end of 2024, so don't rush). [2023.12.14] We have made supplementary materials and demo available at this page. [2023.11.04] We have made Prompt2Sign and Tools available at GitHub. Check out here.</p>"},{"location":"#superset-introduction","title":"Superset Introduction","text":"<p>Prompt2Sign is first comprehensive multilingual sign language superset, which uses tools to automate the acquisition and processing of sign language videos on the web, is an evolving data set that is efficient, lightweight, reducing the previous shortcomings.  The details of the  are available at https://signllm.github.io/Prompt2Sign/.</p> <p>Current languages include: American Sign Language (ASL), German Sign Language (GSL, Alias DGS), Swiss German Sign Language (DSGS), French Sign Language of Switzerland (LSF-CH), Italian Sign Language of Switzerland (LIS-CH), Argentine Sign Language (Lengua de Se\u00f1as Argentina, LSA), Korean Sign Language (KSL), and Turkish Sign Language (TSL).</p> <p></p>"},{"location":"#how-to-cite","title":"How To Cite","text":"<p>Please cite the following paper when using Prompt2Sign in your research:</p> <pre><code>@misc{fang2025signllmsignlanguageproduction,\n      title={SignLLM: Sign Language Production Large Language Models}, \n      author={Sen Fang and Chen Chen and Lei Wang and Ce Zheng and Chunyu Sui and Yapeng Tian},\n      year={2025},\n      eprint={2405.10718},\n      archivePrefix={arXiv},\n      primaryClass={cs.CV},\n      url={https://arxiv.org/abs/2405.10718}, \n}\n\n@misc{fang2025signdiffdiffusionmodelamerican,\n      title={SignDiff: Diffusion Model for American Sign Language Production}, \n      author={Sen Fang and Chunyu Sui and Yanghao Zhou and Xuedong Zhang and Hongbin Zhong and Yapeng Tian and Chen Chen},\n      year={2025},\n      eprint={2308.16082},\n      archivePrefix={arXiv},\n      primaryClass={cs.CV},\n      url={https://arxiv.org/abs/2308.16082}, \n}\n</code></pre>"},{"location":"FAQ/","title":"FAQ","text":"<p>Are there dataloaders available for the dataset.</p> <p>Two answers: Yes &amp; coming soon. For each of the benchmarks, there is a dataloader available that was used to generate the benchmark results and that should cover most purposes. There's also a set of common dataloaders coming, which will be available sometime in next year.</p>"},{"location":"acknowledgements/","title":"Acknowledgements","text":"<p>All data collection and processing are conducted in accordance with the relevant certificates/protocols of the used dataset. For data sets that are public but require a license, we provide processing tools with the permission of the relevant certificate.</p> <p>Licensing</p> <p>Prompt2Sign is made available under the Creative Commons Attribution-NonCommercial 4.0 International License. For commercial use, please contact us directly.</p> <p></p>"},{"location":"contactUs/","title":"Contact Us","text":"<p>Join the conversation and contribute to the pioneering work we are doing at Prompt2Sign!</p> <p>For questions/suggestions of data/code issues, please raise on issue on the Code Repo or Tool Repo. For direct contact, press inquiries or any concerns: Email Us.</p>"},{"location":"downloadData/","title":"downloadData","text":"<p>Prompt2Sign ASL part</p> <ul> <li>https://drive.google.com/file/d/</li> </ul> <p>It can be used in the training of ASL production/recognition models.</p> <p>Prompt2Sign GSL part</p> <ul> <li>https://drive.google.com/file/d/</li> </ul> <p>It can be used in the training of GSL production/recognition models.</p> <p>Prompt2Sign DSGS part</p> <ul> <li>https://drive.google.com/file/d/</li> </ul> <p>It can be used in the training of DSGS production/recognition models.</p> <p>Prompt2Sign LSF-CH part</p> <ul> <li>https://drive.google.com/file/d/</li> </ul> <p>It can be used in the training of LSF-CH production/recognition models.</p> <p>Prompt2Sign LIS-CH part</p> <ul> <li>https://drive.google.com/file/d/</li> </ul> <p>It can be used in the training of LIS-CH production/recognition models.</p> <p>Prompt2Sign LSA part</p> <ul> <li>https://drive.google.com/file/d/</li> </ul> <p>It can be used in the training of LSA production/recognition models.</p> <p>Prompt2Sign KSL part</p> <ul> <li>https://drive.google.com/file/d/</li> </ul> <p>It can be used in the training of KSL production/recognition models.</p> <p>Prompt2Sign TSL part</p> <ul> <li>https://drive.google.com/file/d/</li> </ul> <p>It can be used in the training of TSL production/recognition models.</p>"},{"location":"howtoCite/","title":"How To Cite","text":"<p>Please cite the following paper when using Prompt2Sign in your research:</p> <pre><code>@misc{fang2025signllmsignlanguageproduction,\n      title={SignLLM: Sign Language Production Large Language Models}, \n      author={Sen Fang and Chen Chen and Lei Wang and Ce Zheng and Chunyu Sui and Yapeng Tian},\n      year={2025},\n      eprint={2405.10718},\n      archivePrefix={arXiv},\n      primaryClass={cs.CV},\n      url={https://arxiv.org/abs/2405.10718}, \n}\n\n@misc{fang2025signdiffdiffusionmodelamerican,\n      title={SignDiff: Diffusion Model for American Sign Language Production}, \n      author={Sen Fang and Chunyu Sui and Yanghao Zhou and Xuedong Zhang and Hongbin Zhong and Yapeng Tian and Chen Chen},\n      year={2025},\n      eprint={2308.16082},\n      archivePrefix={arXiv},\n      primaryClass={cs.CV},\n      url={https://arxiv.org/abs/2308.16082}, \n}\n</code></pre> <p>Related Work</p> <p><sup>1</sup>SignLLM: Sign Languages Production Large Language Models.</p> <p><sup>2</sup>SignDiff: Learning Diffusion Models for American Sign Language Production.</p>"},{"location":"download/ASL/","title":"ASL Part","text":"<p>Download link</p> <p>V1 News: After preprocessing How2Sign dataset by OpenPose, the condensed data set obtained is as follows:</p> <ul> <li>https://drive.google.com/file/d/</li> </ul> <p>Optional backup data: </p> <ul> <li>https://huggingface.co/datasets/SignDiff/how2sign-pre.zip</li> </ul> <p>It can be used in the training of ASL production/recognition models.</p>"},{"location":"download/DSGS/","title":"DSGS Part","text":"<p>Download link</p> <p>V1 News: After preprocessing Signsuisse (DSGS/LSF/LIS lexicon) dataset by OpenPose, the condensed data set obtained is as follows:</p> <ul> <li>Due to the prohibition of any form of redistribution, please download the original dataset and process it yourself.</li> </ul> <p>Optional backup data: </p> <ul> <li></li> </ul> <p>It can be used in the training of DSGS production/recognition models.</p>"},{"location":"download/GSL/","title":"GSL Part","text":"<p>Download link</p> <p>V1 News: After preprocessing Phoenix-14T dataset by OpenPose, the condensed data set obtained is as follows:</p> <ul> <li>https://drive.google.com/file/d/</li> </ul> <p>Optional backup data: </p> <ul> <li>https://huggingface.co/datasets/SignDiff/phoenix-pre.zip</li> </ul> <p>It can be used in the training of GSL production/recognition models.</p>"},{"location":"download/KSL/","title":"KSL Part","text":"<p>Download link</p> <p>V1 News: After preprocessing Korean Sign Language (KSL) dataset by OpenPose, the condensed data set obtained is as follows:</p> <p>Optional backup data: </p> <p>It can be used in the training of KSL production/recognition models.</p>"},{"location":"download/LIS-CH/","title":"LIS-CH Part","text":"<p>Download link</p> <p>V1 News: After preprocessing Signsuisse (DSGS/LSF/LIS lexicon) dataset by OpenPose, the condensed data set obtained is as follows:</p> <ul> <li>Due to the prohibition of any form of redistribution, please download the original dataset and process it yourself.</li> </ul> <p>Optional backup data: </p> <ul> <li></li> </ul> <p>It can be used in the training of LIS-ch production/recognition models.</p>"},{"location":"download/LSA/","title":"LSA Part","text":"<p>Download link</p> <p>V1 News: After preprocessing LSA64 dataset by OpenPose, the condensed data set obtained is as follows:</p> <p>Optional backup data: </p> <p>It can be used in the training of LSA production/recognition models.</p>"},{"location":"download/LSF-CH/","title":"LSF-CH Part","text":"<p>Download link</p> <p>V1 News: After preprocessing Signsuisse (DSGS/LSF/LIS lexicon) dataset by OpenPose, the condensed data set obtained is as follows:</p> <ul> <li>Due to the prohibition of any form of redistribution, please download the original dataset and process it yourself.</li> </ul> <p>Optional backup data: </p> <ul> <li></li> </ul> <p>It can be used in the training of LSF-ch production/recognition models.</p>"},{"location":"download/TSL/","title":"TSL Part","text":"<p>Download link</p> <p>Download link</p> <p>V1 News: After preprocessing AUTSL dataset by OpenPose, the condensed data set obtained is as follows:</p> <ul> <li>Due to the prohibition of any form of redistribution, please download the original dataset and process it yourself.</li> </ul> <p>Optional backup data: </p> <ul> <li>Search by bing</li> <li>https://github.com/jackyjsy/CVPR21Chal-SLR</li> <li>https://github.com/MegaYEye/ChaLearn_2021_Looking_at_People_Large_Scale_Signer_Independent_Isolated_SLR_CVPR_Challenge</li> </ul> <p>It can be used in the training of TSL production/recognition models.</p>"},{"location":"tool4data/2Dto3D/","title":"2D to 3D","text":"<p>2dto3d </p>"},{"location":"tool4data/cleanTool/","title":"Clean Tool","text":"<p>cleantool </p>"},{"location":"tool4data/tools_list/","title":"All links","text":"<p>List of our data collection tools:</p> <ul> <li> <p>https://github.com/SignLLM/Prompt2Sign/tools/Clean_Tool</p> </li> <li> <p>https://github.com/SignLLM/Prompt2Sign/tools/2D_to_3D</p> </li> <li> <p>https://github.com/SignLLM/Prompt2Sign/tools/Prompt_Tool</p> </li> <li> <p>https://github.com/SignLLM/Prompt2Sign/tools/Common_Tool</p> </li> </ul> <p>Details coming Soon, you can take a look at our project homepage, which is actually quite detailed.</p>"}]}